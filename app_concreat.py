# app.py
import io
import os
import time
import tempfile
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, regularizers

st.set_page_config(page_title="ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆå¼·åº¦ äºˆæ¸¬ANN", layout="wide")

# -----------------------
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# -----------------------
@st.cache_data
def load_csv(file, encoding, sep):
    return pd.read_csv(file, encoding=encoding, sep=sep)

def available_numeric_columns(df: pd.DataFrame):
    # æ•°å€¤ã«å¼·åˆ¶å¤‰æ›ã—ã¦ã‚‚NaNå°‘ãªã‚ã®åˆ—ã‚’å„ªå…ˆ
    num_cols = []
    for c in df.columns:
        try:
            pd.to_numeric(df[c], errors="raise")
            num_cols.append(c)
        except Exception:
            pass
    return num_cols

def parse_hidden_layers(text: str):
    # "128,128,64" -> [128,128,64]
    try:
        units = [int(x.strip()) for x in text.split(",") if x.strip() != ""]
        return [u for u in units if u > 0]
    except Exception:
        return [128, 128, 64]

def build_model(input_dim: int, hidden_units, dropout, l2reg, lr):
    inputs = keras.Input(shape=(input_dim,))
    x = inputs
    for u in hidden_units:
        x = layers.Dense(
            u, activation="relu",
            kernel_regularizer=regularizers.l2(l2reg) if l2reg > 0 else None
        )(x)
        if dropout > 0:
            x = layers.Dropout(dropout)(x)
    outputs = layers.Dense(1, activation="linear")(x)

    model = keras.Model(inputs, outputs)
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=lr),
        loss="mse",
        metrics=[keras.metrics.RootMeanSquaredError(name="rmse"), "mae"]
    )
    return model

def metrics_table(y_true, y_pred):
    rmse = mean_squared_error(y_true, y_pred, squared=False)
    mae  = mean_absolute_error(y_true, y_pred)
    r2   = r2_score(y_true, y_pred)
    return pd.DataFrame(
        {"RMSE":[rmse], "MAE":[mae], "R^2":[r2]}
    )

def plot_true_vs_pred(y_true, y_pred, title="True vs Pred"):
    fig, ax = plt.subplots()
    ax.scatter(y_true, y_pred, alpha=0.6)
    lo = min(y_true.min(), y_pred.min())
    hi = max(y_true.max(), y_pred.max())
    ax.plot([lo, hi], [lo, hi], linestyle="--")
    ax.set_xlabel("True")
    ax.set_ylabel("Predicted")
    ax.set_title(title)
    st.pyplot(fig)

# -----------------------
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šãƒ‡ãƒ¼ã‚¿å…¥åŠ›
# -----------------------
st.sidebar.header("1) ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿")
uploaded = st.sidebar.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"])
encoding = st.sidebar.selectbox("æ–‡å­—ã‚³ãƒ¼ãƒ‰", ["utf-8", "cp932", "shift_jis"], index=0)
sep = st.sidebar.selectbox("åŒºåˆ‡ã‚Š", [",", ";", "\t", "|"], index=0)

df = None
if uploaded is not None:
    try:
        df = load_csv(uploaded, encoding=encoding, sep=sep)
    except Exception as e:
        st.sidebar.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

if df is None:
    st.info("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

st.write("### ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
st.dataframe(df.head(20), use_container_width=True)

# åˆ—é¸æŠï¼ˆæ•°å€¤åˆ—ã‚’å€™è£œã«ï¼‰
num_cols = available_numeric_columns(df)
if len(num_cols) == 0:
    st.error("æ•°å€¤åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ•°å€¤åˆ—ã‚’å«ã‚€CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

st.sidebar.header("2) åˆ—ã®æŒ‡å®š")
default_target = "strength" if "strength" in df.columns else num_cols[-1]
target_col = st.sidebar.selectbox("ç›®çš„å¤‰æ•°ï¼ˆäºˆæ¸¬ã—ãŸã„åˆ—ï¼‰", options=num_cols, index=num_cols.index(default_target) if default_target in num_cols else 0)

default_features = [c for c in ["cement","slag","flyash","water","superplasticizer","coarseagg","fineagg","age"] if c in num_cols and c != target_col]
if not default_features:
    # ç›®çš„å¤‰æ•°ä»¥å¤–ã®ä¸Šä½8åˆ—ã‚’åˆæœŸå€¤ã«
    default_features = [c for c in num_cols if c != target_col][:8]

feature_cols = st.sidebar.multiselect(
    "èª¬æ˜å¤‰æ•°ï¼ˆè¤‡æ•°é¸æŠï¼‰", options=[c for c in num_cols if c != target_col],
    default=default_features
)

if len(feature_cols) == 0:
    st.warning("å°‘ãªãã¨ã‚‚1ã¤ã®èª¬æ˜å¤‰æ•°ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚")
    st.stop()

# -----------------------
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šå‰å‡¦ç†ãƒ»åˆ†å‰²
# -----------------------
st.sidebar.header("3) å‰å‡¦ç†ãƒ»åˆ†å‰²")
test_size = st.sidebar.slider("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å‰²åˆ", 0.05, 0.5, 0.2, 0.05)
do_log_age = False
if "age" in feature_cols:
    do_log_age = st.sidebar.checkbox("ageã‚’log1på¤‰æ›ï¼ˆä»»æ„ï¼‰", value=False)

# -----------------------
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šãƒ¢ãƒ‡ãƒ«è¨­å®š
# -----------------------
st.sidebar.header("4) ãƒ¢ãƒ‡ãƒ«è¨­å®šï¼ˆKerasï¼‰")
hidden_text = st.sidebar.text_input("éš ã‚Œå±¤ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰", value="128,128,64", help="ä¾‹: 256,128,64")
dropout = st.sidebar.slider("Dropout", 0.0, 0.8, 0.1, 0.05)
l2reg = st.sidebar.number_input("L2æ­£å‰‡åŒ–ï¼ˆÎ»ï¼‰", min_value=0.0, value=0.0, step=0.0001, format="%.4f")
lr = st.sidebar.number_input("å­¦ç¿’ç‡ï¼ˆAdamï¼‰", min_value=1e-5, max_value=1e-1, value=1e-3, step=1e-5, format="%.5f")
epochs = st.sidebar.number_input("ã‚¨ãƒãƒƒã‚¯æ•°", min_value=10, max_value=5000, value=1000, step=10)
batch_size = st.sidebar.selectbox("ãƒãƒƒãƒã‚µã‚¤ã‚º", [16, 32, 64, 128], index=1)
early_patience = st.sidebar.slider("EarlyStopping patience", 10, 200, 50, 5)

train_button = st.sidebar.button("ğŸ” å­¦ç¿’ã‚’å®Ÿè¡Œ")

# -----------------------
# ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
# -----------------------
data = df.copy()

# æ•°å€¤åŒ–ã‚’ä¿è¨¼ï¼ˆæ–‡å­—åˆ—ã®æ•°å€¤ã‚‚å–ã‚Šè¾¼ã‚€ï¼‰
for c in feature_cols + [target_col]:
    data[c] = pd.to_numeric(data[c], errors="coerce")

data = data.dropna(subset=feature_cols + [target_col]).reset_index(drop=True)

# ä»»æ„: ageã®log1på¤‰æ›
effective_features = feature_cols.copy()
if do_log_age and "age" in effective_features:
    data["age_log"] = np.log1p(data["age"].astype(float))
    effective_features = [("age_log" if c == "age" else c) for c in effective_features]

X = data[effective_features].values.astype("float32")
y = data[target_col].values.astype("float32")

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=test_size, random_state=42
)

scaler = StandardScaler()
X_train_sc = scaler.fit_transform(X_train)
X_test_sc  = scaler.transform(X_test)

st.write("**èª¬æ˜å¤‰æ•°**:", effective_features)
st.write("**ç›®çš„å¤‰æ•°**:", target_col)
st.write(f"å­¦ç¿’ç”¨: {X_train_sc.shape}, ãƒ†ã‚¹ãƒˆç”¨: {X_test_sc.shape}")

# -----------------------
# å­¦ç¿’
# -----------------------
if "model" not in st.session_state:
    st.session_state.model = None
if "scaler" not in st.session_state:
    st.session_state.scaler = None
if "history" not in st.session_state:
    st.session_state.history = None
if "features" not in st.session_state:
    st.session_state.features = effective_features
if "target" not in st.session_state:
    st.session_state.target = target_col

if train_button:
    hidden_units = parse_hidden_layers(hidden_text)
    model = build_model(
        input_dim=X_train_sc.shape[1],
        hidden_units=hidden_units,
        dropout=dropout,
        l2reg=l2reg,
        lr=lr
    )

    callbacks = [
        keras.callbacks.EarlyStopping(
            monitor="val_rmse", patience=int(early_patience), restore_best_weights=True
        )
    ]

    with st.spinner("å­¦ç¿’ä¸­..."):
        history = model.fit(
            X_train_sc, y_train,
            validation_split=0.2,
            epochs=int(epochs),
            batch_size=int(batch_size),
            callbacks=callbacks,
            verbose=0
        )

    st.session_state.model = model
    st.session_state.scaler = scaler
    st.session_state.history = history.history
    st.session_state.features = effective_features
    st.session_state.target = target_col

    st.success("å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ä¸‹ã«è©•ä¾¡çµæœã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")

# -----------------------
# è©•ä¾¡ã¨å¯è¦–åŒ–
# -----------------------
if st.session_state.model is not None:
    model = st.session_state.model
    scaler = st.session_state.scaler

    y_pred_test = model.predict(X_test_sc, verbose=0).reshape(-1)
    y_pred_train = model.predict(X_train_sc, verbose=0).reshape(-1)

    st.subheader("è©•ä¾¡æŒ‡æ¨™")
    col1, col2 = st.columns(2)
    with col1:
        st.write("**ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿**")
        st.dataframe(metrics_table(y_test, y_pred_test), use_container_width=True)
    with col2:
        st.write("**å­¦ç¿’ãƒ‡ãƒ¼ã‚¿**")
        st.dataframe(metrics_table(y_train, y_pred_train), use_container_width=True)

    st.subheader("äºˆæ¸¬ã®å¯è¦–åŒ–")
    col3, col4 = st.columns(2)
    with col3:
        plot_true_vs_pred(y_test, y_pred_test, title="Test: True vs Pred")
    with col4:
        plot_true_vs_pred(y_train, y_pred_train, title="Train: True vs Pred")

    if st.session_state.history:
        st.subheader("å­¦ç¿’æ›²ç·š")
        hist = st.session_state.history
        fig, ax = plt.subplots()
        ax.plot(hist["rmse"], label="rmse")
        ax.plot(hist["val_rmse"], label="val_rmse")
        ax.set_xlabel("epoch")
        ax.set_ylabel("RMSE")
        ax.legend()
        st.pyplot(fig)

    # -------------------
    # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    # -------------------
    st.subheader("ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜")
    c1, c2 = st.columns(2)
    with c1:
        with tempfile.TemporaryDirectory() as tmpd:
            model_path = os.path.join(tmpd, "best_concrete_ann.keras")
            st.session_state.model.save(model_path, include_optimizer=True)
            with open(model_path, "rb") as f:
                st.download_button(
                    label="å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ï¼ˆ.kerasï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=f.read(),
                    file_name="best_concrete_ann.keras",
                    mime="application/octet-stream"
                )
    with c2:
        # scaler ã‚’npzã§ä¿å­˜ï¼ˆå¹³å‡ãƒ»åˆ†æ•£ãƒ»scaleãªã©ï¼‰
        buf = io.BytesIO()
        np.savez(
            buf,
            mean_=scaler.mean_,
            scale_=scaler.scale_,
            var_=scaler.var_,
            n_features_in_=np.array([scaler.n_features_in_]),
        )
        st.download_button(
            label="æ¨™æº–åŒ–ã‚¹ã‚±ãƒ¼ãƒ©ï¼ˆ.npzï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=buf.getvalue(),
            file_name="scaler_concrete.npz",
            mime="application/octet-stream"
        )

# -----------------------
# å˜ç™ºæ¨è«–ï¼ˆãƒ•ã‚©ãƒ¼ãƒ ï¼‰
# -----------------------
st.subheader("å˜ç™ºæ¨è«–ï¼ˆèª¬æ˜å¤‰æ•°ã‚’å…¥åŠ›ï¼‰")
if st.session_state.model is None:
    st.info("å…ˆã«å­¦ç¿’ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
else:
    model = st.session_state.model
    scaler = st.session_state.scaler
    feat_names = st.session_state.features

    cols = st.columns(min(4, len(feat_names)))
    values = []
    for i, name in enumerate(feat_names):
        col = cols[i % len(cols)]
        # åˆæœŸå€¤ã¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ä¸­å¤®å€¤
        default_val = float(np.median(data[name]))
        val = col.number_input(name, value=default_val)
        values.append(val)

    if st.button("ã“ã®å…¥åŠ›ã§äºˆæ¸¬ã™ã‚‹"):
        x = np.array(values, dtype="float32").reshape(1, -1)
        x_sc = scaler.transform(x)
        yhat = model.predict(x_sc, verbose=0).reshape(-1)[0]
        st.success(f"äºˆæ¸¬å¼·åº¦: **{yhat:.3f}**")

st.caption("Â© Streamlit + TensorFlow/Keras | CSVã®åˆ—åã¯UIã‹ã‚‰è‡ªç”±ã«æŒ‡å®šã§ãã¾ã™ã€‚")
